{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d2f2dc8",
      "metadata": {},
      "source": [
        "# Introduction to PCA\n",
        "\n",
        "PCA is used for dimensionality reduction. This notebook is based on [In Depth: Principal Component Analysis](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html), with extensions to show what PCA means in practice.\n",
        "\n",
        "PCA is a relatively advanced technique for feature engineering. It is used when there is a lot of collinearity between the features, but it is difficult to decide which features to drop.\n",
        "\n",
        "PCA takes a set of $n$ features and generates a scaled and rotated set of $p$ features, where $p < n$.\n",
        "The features derived by PCA are called the _Principal Components_ of the original features.\n",
        "For example, size and weight might be heavily correlated (highly collinear) features. We could drop one or the other. PCA derives a new feature which has elements of both `size` _and_ `weight`, and which might be a better predictor than either `size` or `weight` on their own.\n",
        "\n",
        "We will cover PCA (and how it works) in class. for the moment, it is enough just to see it in action in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dad1f85",
      "metadata": {
        "tags": [
          "imports"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8000654",
      "metadata": {},
      "source": [
        "We create some functions for later use. `drawVector` allows us to show the principal component axes on a plot. `abline` allows us to draw a line, given its slope and intercept, analogous to R's `abline` function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3bada5e",
      "metadata": {
        "lines_to_next_cell": 1,
        "tags": [
          "draw_vector"
        ]
      },
      "outputs": [],
      "source": [
        "def draw_vector(v0, v1, ax=None):\n",
        "    ax = ax or plt.gca()\n",
        "    arrowprops=dict(arrowstyle='->',\n",
        "                    linewidth=2,\n",
        "                    shrinkA=0, shrinkB=0)\n",
        "    ax.annotate('', v1, v0, arrowprops=arrowprops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84c3241e",
      "metadata": {
        "tags": [
          "abline"
        ]
      },
      "outputs": [],
      "source": [
        "# See https://stackoverflow.com/a/43811762\n",
        "def abline(slope, intercept):\n",
        "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
        "    axes = plt.gca()\n",
        "    x_vals = np.array(axes.get_xlim())\n",
        "    y_vals = intercept + slope * x_vals\n",
        "    plt.plot(x_vals, y_vals, '--')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ba80ff",
      "metadata": {},
      "source": [
        "We generate some 2-D random data points. The point cloud has an elongated shape by design. Therefore the first principal component is expected to align with the main axis of the data, and the second principal component would be orthogonal to the first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e9e1e8",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf32c464",
      "metadata": {
        "tags": [
          "generated_pointCloud"
        ]
      },
      "outputs": [],
      "source": [
        "rng = np.random.RandomState(1)\n",
        "X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
        "print(X[0:4,:])\n",
        "\n",
        "#X = np.random.randint(2, size=(100,30))\n",
        "#print(X[0:4,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47dd260b",
      "metadata": {},
      "source": [
        "Now that we have the 2-D point cloud, we derive its first and second principal components and display how much variance is explained by the first and second. As can be seen, most of the variance is associated with the first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758aa971",
      "metadata": {
        "tags": [
          "fitPCA"
        ]
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca.fit(X)\n",
        "explainedVariance = pca.explained_variance_\n",
        "v1=explainedVariance[0]\n",
        "v2=explainedVariance[1]\n",
        "pca.explained_variance_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69958670",
      "metadata": {
        "variables": {
          "explainedVariance[0]": "0.7625315008826112",
          "explainedVariance[1]": "0.018477895513562572"
        }
      },
      "source": [
        "In other words, the first PC explains {{explainedVariance[0]}} with a variance of {{explainedVariance[1]}} left over for the second (and last) PC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d87fec",
      "metadata": {
        "tags": [
          "printPCAcomponents"
        ]
      },
      "outputs": [],
      "source": [
        "e = pca.components_\n",
        "pca.components_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b659be",
      "metadata": {
        "variables": {
          "e[0][0]": "-0.9444602872084233",
          "e[0][1]": "-0.32862557095603917",
          "e[1][0]": "-0.32862557095603917",
          "e[1][1]": "0.9444602872084233"
        }
      },
      "source": [
        "The PC components above are the eigenvectors that define the directions of the first and second PCs. After translating the data so its mean is at the origin, the first PC can be written in the form `(-0.944x_1 + -0.329x_2 = 0` and the second PC is perpendicular to it and can be written in the form `(-0.329x_1 + 0.944x_2 = 0`.\n",
        "\n",
        "We can now plot the data (in its original position) and overlay `PC_1` which runs along the main axis of the data and `PC_2` which is perpendicular to it. Note that the principal components have been scaled according to the amount of variance they explain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60558e72",
      "metadata": {
        "lines_to_next_cell": 2,
        "tags": [
          "plotScreeDiag"
        ]
      },
      "outputs": [],
      "source": [
        "# plot data\n",
        "plt.scatter(X[:, 0], X[:, 1], alpha=0.1)\n",
        "plt.axis('equal')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('input')\n",
        "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
        "    v = vector * 3 * np.sqrt(length)\n",
        "    draw_vector(pca.mean_, pca.mean_ + v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89657cdd",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53cd58a4",
      "metadata": {
        "tags": [
          "plotPrincipalComponents"
        ]
      },
      "outputs": [],
      "source": [
        "# plot principal components\n",
        "X_pca = pca.transform(X)\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.2)\n",
        "draw_vector([0, 0], [0, 3])\n",
        "draw_vector([0, 0], [3, 0])\n",
        "plt.axis('equal')\n",
        "plt.xlabel(\"component 1 pc1\")\n",
        "plt.ylabel('component 2 pc2')\n",
        "plt.title('Data is rotated to align with the principal components')\n",
        "plt.xlim=(-5, 5)\n",
        "plt.ylim=(-5, 5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b343e98",
      "metadata": {},
      "source": [
        "If we rerun the PCA operation, but this time decide to keep only the leading principal components that explain at least 95% of the variance, we see that the second principal component can be ignored and we find a lower dimensional representation `X_trans` of the original data (1-D instead of 2-D)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a7c8129",
      "metadata": {
        "tags": [
          "fitPCA095"
        ]
      },
      "outputs": [],
      "source": [
        "clf = PCA(0.95) # keep 95% of variance\n",
        "X_trans = clf.fit_transform(X)\n",
        "print(X.shape)\n",
        "print(X_trans.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89026527",
      "metadata": {},
      "source": [
        "We can compare the reduced dimension `X_trans` to the original `X` - see the following plot. As you can see, the original `X` points have been projected onto the PC_1 line. Because the points lie upon a line, each point maps to a value on the `PC_1` line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "973aed4d",
      "metadata": {
        "tags": [
          "comparePCAvsOrig"
        ]
      },
      "outputs": [],
      "source": [
        "X_new = clf.inverse_transform(X_trans)\n",
        "plt.plot(X[:, 0], X[:, 1], 'o', alpha=0.1)\n",
        "plt.plot(X_new[:, 0], X_new[:, 1], 'ob', alpha=0.8)\n",
        "ab1 = clf.components_[0]\n",
        "abline(slope=ab1[1]/ab1[0], intercept=0)\n",
        "plt.axis('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3ee15a0",
      "metadata": {},
      "source": [
        "We can make the 1-D nature of `X_trans` more obvious by rotating both the original `X` and the transformed `X_trans` so that their `PC_1` is horizontal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8db4d745",
      "metadata": {
        "tags": [
          "getRotCS"
        ]
      },
      "outputs": [],
      "source": [
        "# Derive the rotation parameters (Cosine and Sine) of the rotation angle\n",
        "C = -ab1[0]\n",
        "S = ab1[1]\n",
        "Q = np.vstack([[C, S], [-S, C]])\n",
        "# Xrot is the points rotated so they are aligned with the first principal component direction\n",
        "Xrot = np.matmul(X,Q)\n",
        "X_newrot = np.matmul(X_new,Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f60274b",
      "metadata": {
        "tags": [
          "plotXrot"
        ]
      },
      "outputs": [],
      "source": [
        "plt.plot(Xrot[:, 0], Xrot[:, 1], 'ob', alpha=0.1)\n",
        "plt.plot(X_newrot[:, 0], X_newrot[:, 1], 'ob', alpha=0.8)\n",
        "plt.axis('equal')\n",
        "abline(slope=0, intercept=0)\n",
        "plt.title('Data is projected onto the first principal component direction')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
