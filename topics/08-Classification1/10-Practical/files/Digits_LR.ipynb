{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00121f20",
      "metadata": {},
      "source": [
        "# Optical Character Recognition for MNIST handwritten characters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06b8893",
      "metadata": {},
      "source": [
        "OCR (Optical Character Recognition) is another classification problem. In this example, we wish to recognise hand-written digits from the famous NIST dataset, each of which is presented as an $8\\times 8$ array of pixel intensities.\n",
        "\n",
        "We are just going to focus on the problem of classifying each rasterised digit scan, and not on the other steps which include tokenising text, basic data cleaning etc.\n",
        "\n",
        "scikit-learn includes a built-in set of pre-formatted digits which we can use. The set is actually the MNIST (Modified NIST) set, but is functionally equivalent to the original NIST set, in relation to its classification challenges.\n",
        "\n",
        "## Looking at the data\n",
        "\n",
        "The data is included in `scikit-learn` and so can be loaded easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d4d68e",
      "metadata": {
        "tags": [
          "load"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "digits = datasets.load_digits()\n",
        "digits.images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd4b78ea",
      "metadata": {},
      "source": [
        "As usual, we review the training data before doing anything else. In this case, the data takes the form of rasterised images, so it makes sense to display them as such, overlaying each image with the label it was assigned by a human."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195ed383",
      "metadata": {
        "tags": [
          "firstLook"
        ]
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n",
        "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
        "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
        "            transform=ax.transAxes, color='green')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "423fba26",
      "metadata": {},
      "source": [
        "Here the data per digit is simply each pixel value within an 8x8 grid. The example grid below represents a zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97737f3",
      "metadata": {
        "tags": [
          "quickView"
        ]
      },
      "outputs": [],
      "source": [
        "# The images themselves\n",
        "print(digits.images.shape)\n",
        "print(digits.images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aad8ee0a",
      "metadata": {},
      "source": [
        "While it is better to display each instance as an 8x8 grid, each instance needs to be flattened into a single row with 64 elements (columns), as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c5cc99",
      "metadata": {
        "tags": [
          "flattenedData"
        ]
      },
      "outputs": [],
      "source": [
        "# The flattened data that is used to train the model.\n",
        "print(digits.data.shape)\n",
        "print(digits.data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4459a89",
      "metadata": {},
      "source": [
        "There are some nice facilities to count the number of different digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6932d34d",
      "metadata": {
        "tags": [
          "targetLabel"
        ]
      },
      "outputs": [],
      "source": [
        "# The target label\n",
        "from collections import Counter # https://stackoverflow.com/a/2392948\n",
        "c = Counter(digits.target)\n",
        "\n",
        "print(c.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5920abba",
      "metadata": {},
      "source": [
        "Summarising, the data has 1797 samples in 64 dimensions and 10 ($0,\\ldots,9$) levels. The number of instances per level varies from 174 to 183."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ada86ee",
      "metadata": {},
      "source": [
        "## Classifying the digits using logistic regression\n",
        "\n",
        "Logistic regression is an extension of regression where a change of variable is used to map the continuous (numerical-valued) prediction into categorical values for classification purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5406dad",
      "metadata": {
        "tags": [
          "trainTestSplit"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "seed=2\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target,\n",
        "                                                random_state=seed, stratify=digits.target)\n",
        "print(Xtrain.shape, Xtest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c7a437",
      "metadata": {},
      "source": [
        "We use logistic regression to classify the scanned written digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5612e64e",
      "metadata": {
        "tags": [
          "LRfit"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Get and configure a LogisticRegression object\n",
        "clf = LogisticRegression(max_iter=7600)\n",
        "\n",
        "# Fit the training data\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "# Using the beta parameters that have been learned and are in clf, predict (recognise) the test data\n",
        "ypred = clf.predict(Xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de3f3afa",
      "metadata": {},
      "source": [
        "We check the classification accuracy score and confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f6f2e1",
      "metadata": {
        "tags": [
          "LRmetrics"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "print(accuracy_score(ytest, ypred))\n",
        "confusionMat = confusion_matrix(ytest, ypred)\n",
        "print(confusionMat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06d2698f",
      "metadata": {},
      "source": [
        "As can be seen, the confusion matrix has several off-diagonal nonzero terms. Because there are 10 labels, the confusion matrix is slightly harder to visualise than the Iris data, which had just 3 labels. We can get a better sense of its layout by plotting it as an image. Because all the values are nonnegative, but there is a large difference in size from the smallest (0) to the largest (45) with most values being at each end of the range, the square root of the values maps better into the Blue colour space used in the plot below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f856126f",
      "metadata": {},
      "source": [
        "Make sure the directory exists beforehand to store the generated plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad202bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "picDir = \"output/LR\"\n",
        "if not os.path.exists(picDir):\n",
        "    os.makedirs(picDir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dbe63e5",
      "metadata": {
        "tags": [
          "LRconfusionMatrix"
        ]
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "plt.imshow(np.sqrt(confusionMat),cmap='Blues', interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.ylabel('true')\n",
        "plt.xlabel('predicted');\n",
        "plt.savefig(picDir+\"/logreg_digits_confusionMatrix.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8b8895",
      "metadata": {},
      "source": [
        "We might also take a look at some of the outputs along with their predicted labels. Matching labels are <font color='green'>green</font> (as before) and unmatched labels are <font color='red'>red</font>:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef5f1c5",
      "metadata": {
        "tags": [
          "LRdigitsAccuracy"
        ]
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n",
        "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(Xtest[i].reshape(8, 8), cmap='binary')\n",
        "    ax.text(0.05, 0.05, str(ypred[i]),\n",
        "            transform=ax.transAxes,\n",
        "            color='green' if (ytest[i] == ypred[i]) else 'red')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "fig.savefig(picDir+\"/digitsAccuracyCheck.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50dc0ec5",
      "metadata": {},
      "source": [
        "Where they do not match, it is arguable what the original writing was meant to represent!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2284c4d3",
      "metadata": {},
      "source": [
        "## Comments\n",
        "\n",
        "Logistic Regression using all $8\\times 8 = 64$ pixel values per image might not be very efficient. At the very least there is probably correlation between the 64 features. This will show up as the solver needing many iterations (taking a lot of time) or even failing to converge.\n",
        "\n",
        "With such image data, how would you chose which features (pixels in this case) to keep in the model?\n",
        "\n",
        "An alternative approach is to look for an uncorrelated set of features that capture most of the variance explained by the original 64 features. This makes the solver's task easier, but might weaken the predictive power of the model. In practice the parameter space associated with the uncorrelated set of features generally has much lower dimension than the original set of features from which they were derived. This procedures is known as _dimensionality reduction_ and is the subject of the other notebook in today's practical."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6794948",
      "metadata": {
        "tags": [
          "Exercise"
        ]
      },
      "source": [
        "## Exercise\n",
        "\n",
        "1. Use Principal Components Analysis (PCA) to derive a lower dimensional set of features, and apply Logistic Regression to the resulting reduced dimension dataframe/model.\n",
        "2. Try using [GridSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to find the optimal setting of PCA's `n_components` parameter. You could search over the range 10 to 40, say."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840d5bc1",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
